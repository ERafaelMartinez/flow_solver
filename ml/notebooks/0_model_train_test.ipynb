{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a91a38",
   "metadata": {},
   "source": [
    "# Model/Dataset Train Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af99f0",
   "metadata": {},
   "source": [
    "In this notebook an overfit is done to check the capability of our model's architecture to learn a specific output image from a randomized input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very important! Do not delete! \n",
    "# This adds the parent directory to python's path so it can correctly find \n",
    "# our submodules\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from networks.ReferenceCNN import ReferenceCNN as Model\n",
    "from trainer import Trainer\n",
    "from hyperparameters import Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1658c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688de5b",
   "metadata": {},
   "source": [
    "We first generate the dummy input- and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image is expected output i.e., target\n",
    "# in greyscale (first layer is one channel)\n",
    "image_path = \"../img/sgs_logo.webp\"\n",
    "out_img = np.array(Image.open(image_path).convert(\"L\"))\n",
    "\n",
    "# as input we generate a dummy random\n",
    "# image of the same size (white noise)\n",
    "in_img = np.random.randint(\n",
    "    0, 255, out_img.shape, dtype=np.uint8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6052285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm in and output images are the same size\n",
    "assert out_img.shape == in_img.shape\n",
    "\n",
    "# visualize in and output images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(in_img)\n",
    "plt.show()\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada4ecf",
   "metadata": {},
   "source": [
    "We take the dummy data to build the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Hyperparameters(epochs=4000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36688662",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in_channels = 1\n",
    "n_out_channels = 1\n",
    "\n",
    "# expected shape within the dataloader/train-loop: (batch_size, n_in_channels, height, width)\n",
    "x = torch.tensor(in_img).reshape(params.batch_size, n_in_channels, *in_img.shape)\n",
    "y = torch.tensor(out_img).reshape(params.batch_size, 1, *out_img.shape)\n",
    "\n",
    "# normalize the data\n",
    "x = x / 255.0\n",
    "y = y / 255.0\n",
    "\n",
    "# create tensor dataset and dataloader\n",
    "train_dataset = torch.utils.data.TensorDataset(x, y)\n",
    "training_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=params.batch_size)\n",
    "validation_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=params.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4ccc2",
   "metadata": {},
   "source": [
    "We now train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd638e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model can be instantiated\n",
    "network = Model(\".\")\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=params.learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "trainer = Trainer(optimizer, criterion, training_dataloader, validation_dataloader)\n",
    "losses = trainer.train(network, params.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.load_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416a59c",
   "metadata": {},
   "source": [
    "We now evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = network(x)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f749b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent y predict as image and show it\n",
    "y_predict_img = y_predict.squeeze().detach().numpy()\n",
    "\n",
    "plt.imshow(y_predict_img[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
